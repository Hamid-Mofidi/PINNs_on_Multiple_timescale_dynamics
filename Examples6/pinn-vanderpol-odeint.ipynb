{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# VanDerPol\n\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# We use Python's `functools.partial` to create a new function based on `fast_vanderpol` \n# with \"eps\" set to zero.\nfrom functools import partial\nfrom scipy.integrate import odeint\nfrom sympy import symbols, Eq, solve, Function, Matrix, diff\n#from scipy.integrate import solve_ivp\n\n\n# Define the ODE systems\ndef fast_vanderpol(y, t, eps):\n    x, y = y\n    dxdt = y - (1/3) * x**3 + x\n    dydt = -eps * x\n    return [dxdt, dydt]\n\n# Create a new function, \"fast_subsystem\" with eps=0 based on fast_vanderpol\nfast_subsystem = partial(fast_vanderpol, eps=0)\n\n# Define the Jacobian function\ndef jacobian(func, y):\n    n = len(y)\n    J = np.zeros((n, n))\n    for i in range(n):\n        epsilon = 1e-6  # Small perturbation\n        y_perturbed = np.array(y.copy(), dtype=float)  \n        y_perturbed[i] += epsilon\n        dy = np.array(func(y_perturbed, 0)) - np.array(func(y, 0))\n        J[:, i] = dy / epsilon\n    return J\n\n# Find equilibrium points of fast_subsystem numerically\nequilibrium_points = [np.zeros(len(fast_vanderpol([0, 0], 0, 0)))] # [np.zeros(len(y))]\n\n# Compute Jacobian matrix at each equilibrium point\nfor eq_point in equilibrium_points:\n    J_eq = jacobian(fast_subsystem, eq_point)\n    eigenvalues, eigenvectors = np.linalg.eig(J_eq)\n    print(\"Jacobian Matrix:\")\n    print(J_eq)\n    print(\"Eigenvalues:\")\n    print(eigenvalues)\n    print(\"Eigenvectors:\")\n    print(eigenvectors)\n    print()\n    # Check if any eigenvalue has a pure imaginary part\n    if any(np.imag(eigenvalues) != 0):\n        print(\"The system is NOT NORMALLY HYPERBOLIC. Stopping...\")\n        break\n    else:\n        print(\"The system is NORMALLY HYPERBOLIC. Proceeding...\\n\")\n\n\ndef slow_vanderpol(y, tau, eps):\n    x, y = y\n    dxdt =  (y - (1/3) * x**3 + x)/eps\n    dydt = - x\n    return [dxdtau, dydtau]\n\ndef slow_subsystem(y, tau):\n    x, y = y\n    dxdtau = x / (1 - x ** 2)\n    dydtau = - x\n    return [dxdtau, dydtau]\n\n\n# Initial points x, y, z:\nx_init, y_init = 1.0, 1.0\nprint('The initial points of the BVP:', f\"x_init = {x_init}, y_init = {y_init}\")\n\nt_end = 100\nt  =  np.linspace(0, t_end, 100)\nt2  =  np.linspace(0, -t_end, 100)\neps = 0.01\ntau = eps * t\n\n# Define initial conditions over the slow manifold\nx1, y1 = 2.1, 1.0\nprint('The starting points on the slow manifold:', f\"x1 = {x1}, y1 = {y1}\")\n\ninit_slow = [x1, y1]  \n# Solve the differential equation using odeint\nslow_subsystem_solution = odeint(slow_subsystem, init_slow, tau)\n# Find the time at which x is closest to x=1\nx_values = slow_subsystem_solution[:, 0]  # Extract x values from the solution\nclosest_index = np.argmin(np.abs(x_values - 1))  # Find index with minimum absolute difference\nclosest_time1 = tau[closest_index]  # Corresponding time value\n\nprint('The time at which x is closest to x=1:', closest_time1)\n\n# Extract the last values of x, y on the slow_subsystem\nx2, y2 = slow_subsystem_solution[closest_index]\nprint('The ending points on the slow manifold (piece1):', f\"x2 = {x2}, y2 = {y2}\")\n\nx_end, y_end = -0.5578, 0.5\nprint('The ending points of the BVP:', f\"x_end = {x_end}, y_end = {y_end}\")\n\n\n# solve ODEs\nintit_bvp = [x_init  y_init]\nx_real, y_real = odeint(fast_vanderpol, intit_bvp, t, args=(mu,)).T\n\n\n\n# Exact solution\nx_exact_fast, y_exact_fast, z_exact_fast = fast_solution(t, eps, x_init, y_init, z_init)\n\n\n# Exact solution for the slow system using the final state of the fast system as initial conditions\nx_exact_slow, y_exact_slow, z_exact_slow = slow_solution(tau, eps, x_init, y_init, z_init)\nprint(x_exact_slow[-1], y_exact_slow[-1], z_exact_slow[-1])\n\n\nx_exact_fast2, y_exact_fast2, z_exact_fast2 = fast_solution(t2, eps, x_end, y_end, z_end)\nprint(x_exact_fast2[-1], y_exact_fast2[-1], z_exact_fast2[-1])\n\n# Transform to tensor\nt_tensor = torch.tensor(t.reshape(-1, 1), dtype=torch.float64) \nx_real_fast_tensor = torch.tensor(x_exact_fast.reshape(-1, 1), dtype=torch.float64)\ny_real_fast_tensor = torch.tensor(y_exact_fast.reshape(-1, 1), dtype=torch.float64)\nz_real_fast_tensor = torch.tensor(z_exact_fast.reshape(-1, 1), dtype=torch.float64)\n\ntau_tensor = torch.tensor(tau.reshape(-1, 1), dtype=torch.float64)\nx_real_slow_tensor = torch.tensor(x_exact_slow.reshape(-1, 1), dtype=torch.float64)\ny_real_slow_tensor = torch.tensor(y_exact_slow.reshape(-1, 1), dtype=torch.float64)\nz_real_slow_tensor = torch.tensor(z_exact_slow.reshape(-1, 1), dtype=torch.float64)\n\nt2_tensor = torch.tensor(t2.reshape(-1, 1), dtype=torch.float64)\nx_real_fast2_tensor = torch.tensor(x_exact_fast2.reshape(-1, 1), dtype=torch.float64)\ny_real_fast2_tensor = torch.tensor(y_exact_fast2.reshape(-1, 1), dtype=torch.float64)\nz_real_fast2_tensor = torch.tensor(z_exact_fast2.reshape(-1, 1), dtype=torch.float64)\n\n\ndef input_transform(t_tensor):\n    return torch.cat([t_tensor], dim=1)\n\n\nclass fast_vanderpol_PINN(nn.Module):\n    def __init__(self):\n        super(fast_vanderpol_PINN, self).__init__()\n        self.fc1 = nn.Linear(1, 50)\n        self.fc2 = nn.Linear(50, 50)\n        self.fc3 = nn.Linear(50, 2)\n\n    def forward(self, t):\n        x = F.tanh(self.fc1(t))\n        x = F.tanh(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nclass slow_vanderpol_PINN(nn.Module):\n    def __init__(self):\n        super(slow_vanderpol_PINN, self).__init__()\n        self.fc1 = nn.Linear(1, 50)\n        self.fc2 = nn.Linear(50, 50)\n        self.fc3 = nn.Linear(50, 2)\n\n    def forward(self, tau):\n        x = F.tanh(self.fc1(tau))\n        x = F.tanh(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \nclass fast_vanderpol_PINN2(nn.Module):\n    def __init__(self):\n        super(fast_vanderpol_PINN2, self).__init__()\n        self.fc1 = nn.Linear(1, 50)\n        self.fc2 = nn.Linear(50, 50)\n        self.fc3 = nn.Linear(50, 2)\n\n    def forward(self, t):\n        x = F.tanh(self.fc1(t))\n        x = F.tanh(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\n\ndef loss_func_fast(model, t_tensor, x_exact_fast, y_exact_fast, z_exact_fast, x_init, y_init, z_init, x_T, y_T, z_T, eps, random_points=10):\n    t_tensor.requires_grad = True\n    pred_fast = model(t_tensor)\n    x_pred_fast, y_pred_fast, z_pred_fast = pred_fast[:, 0].unsqueeze(1), pred_fast[:, 1].unsqueeze(1), pred_fast[:, 2].unsqueeze(1)\n    # Compute residuals using torch.autograd.grad\n    def compute_residuals_autograd(system, output, time, epsilon):\n        derivatives = []\n        for idx in range(len(output)):\n            derivative = torch.autograd.grad(output[idx], time, grad_outputs=torch.ones_like(output[idx]), create_graph=True, retain_graph=True)[0]\n            derivatives.append(derivative)\n        residuals = [derivative - output[idx] for idx, derivative in enumerate(derivatives)]\n        return residuals\n    residual_fast_vanderpol_autograd = compute_residuals_autograd(fast_vanderpol, [x_pred_fast, y_pred_fast, z_pred_fast], t_tensor, eps)\n    residual_fast_subsystem_autograd = compute_residuals_autograd(fast_subsystem, [x_pred_fast, y_pred_fast, z_pred_fast], t_tensor, 0)  # eps=0 for fast_subsystem\n    \n    physics_loss_fast = torch.mean(torch.stack(residual_fast_vanderpol_autograd)**2)  +\\\n                        torch.mean(torch.stack(residual_fast_subsystem_autograd)**2)\n   \n    init_loss_fast = torch.square(x_pred_fast[0] - x_init) + torch.square(y_pred_fast[0] - y_init) + torch.square(z_pred_fast[0] - z_init)\n    boundary_loss_fast = torch.square(x_pred_fast[-1] - x_T) + torch.square(y_pred_fast[-1] - y_T) + torch.square(z_pred_fast[-1] - z_T)\n\n    # Combine all loss terms\n    total_loss_fast = physics_loss_fast + init_loss_fast + boundary_loss_fast \n\n    return total_loss_fast\n\ndef loss_func_slow(model, tau_tensor, x_exact_slow, y_exact_slow, z_exact_slow, x1, y1, z1, x_TT, y_TT, z_TT, eps, random_points=10):\n    tau_tensor.requires_grad = True\n    pred_slow = model(tau_tensor)\n    x_pred_slow, y_pred_slow, z_pred_slow = pred_slow[:, 0].unsqueeze(1), pred_slow[:, 1].unsqueeze(1), pred_slow[:, 2].unsqueeze(1)\n    ones = torch.ones_like(x_pred_slow, requires_grad=True)\n    dx_dtau = torch.autograd.grad(x_pred_slow, tau_tensor, grad_outputs=ones, retain_graph=True, create_graph=True)[0]\n    dy_dtau = torch.autograd.grad(y_pred_slow, tau_tensor, grad_outputs=ones, retain_graph=True, create_graph=True)[0]\n    dz_dtau = torch.autograd.grad(z_pred_slow, tau_tensor, grad_outputs=ones, retain_graph=True, create_graph=True)[0]\n\n    residual1_slow = 0  # dx_dtau + x_pred_slow / eps\n    residual2_slow = 0  # dy_dtau - (2 * y_pred_slow + eps * x_pred_slow) / eps\n    residual3_slow = dz_dtau - x_pred_slow**2 - 1\n    init_loss_slow = torch.square(x_pred_slow[0] - x1) + torch.square(y_pred_slow[0] - y1) + torch.square(z_pred_slow[0] - z1)\n    physics_loss_slow = torch.mean(residual1_slow**2 + residual2_slow**2 + residual3_slow**2)\n\n    random_indices = torch.randint(0, x_exact_slow.shape[0], (random_points,))\n    \n    boundary_loss_slow = torch.square(x_pred_slow[-1] - x_TT) + torch.square(y_pred_slow[-1] - y_TT) + torch.square(z_pred_slow[-1] - z_TT)\n    total_loss_slow = physics_loss_slow + init_loss_slow + boundary_loss_slow\n    return total_loss_slow\n\n\ndef loss_func_fast(model, t2_tensor, x_exact_fast2, y_exact_fast2, z_exact_fast2, x_end, y_end, z_end, x2_T, y2_T, z2_T, eps, random_points=10):\n    t2_tensor.requires_grad = True\n    pred_fast2 = model(t2_tensor)\n    x_pred_fast2, y_pred_fast2, z_pred_fast2 = pred_fast2[:, 0].unsqueeze(1), pred_fast2[:, 1].unsqueeze(1), pred_fast2[:, 2].unsqueeze(1)\n    ones = torch.ones_like(x_pred_fast2, requires_grad=True)  \n    dx_dt2 = torch.autograd.grad(x_pred_fast2, t2_tensor, grad_outputs=ones, retain_graph=True, create_graph=True)[0]\n    dy_dt2 = torch.autograd.grad(y_pred_fast2, t2_tensor, grad_outputs=ones, retain_graph=True, create_graph=True)[0]\n    dz_dt2 = torch.autograd.grad(z_pred_fast2, t2_tensor, grad_outputs=ones, retain_graph=True, create_graph=True)[0]\n\n    # Compute residuals for fast_vanderpol\n    residual1_fast2 = dx_dt2 - fast_vanderpol([x_pred_fast2, y_pred_fast2, z_pred_fast2], t2_tensor, eps)[0]\n    residual2_fast2 = dy_dt2 - fast_vanderpol([x_pred_fast2, y_pred_fast2, z_pred_fast2], t2_tensor, eps)[1]\n    residual3_fast2 = dz_dt2 - fast_vanderpol([x_pred_fast2, y_pred_fast2, z_pred_fast2], t2_tensor, eps)[2]\n\n    # Compute residuals for fast_subsystem\n    residual4_fast2 = dx_dt2 - fast_subsystem([x_pred_fast2, y_pred_fast2, z_pred_fast2], t2_tensor)[0]\n    residual5_fast2 = dy_dt2 - fast_subsystem([x_pred_fast2, y_pred_fast2, z_pred_fast2], t2_tensor)[1]\n    residual6_fast2 = dz_dt2 - fast_subsystem([x_pred_fast2, y_pred_fast2, z_pred_fast2], t2_tensor)[2]\n\n    physics_loss_fast2 = torch.mean(residual1_fast2**2 + residual2_fast2**2 + residual3_fast2**2 +\n                                    residual4_fast2**2 + residual5_fast2**2 + residual6_fast2**2)\n\n    init_loss_fast2 = torch.square(x_pred_fast2[0] - x_end) + torch.square(y_pred_fast2[0] - y_end) + torch.square(z_pred_fast2[0] - z_end)\n    boundary_loss_fast2 = torch.square(x_pred_fast2[-1] - x2_T) + torch.square(y_pred_fast2[-1] - y2_T) + torch.square(z_pred_fast2[-1] - z2_T)\n       \n    total_loss_fast2 = physics_loss_fast2 + init_loss_fast2 + boundary_loss_fast2\n\n    return total_loss_fast2\n\n\n\n\ndef total_loss_func(model_fast, model_slow, model_fast2, t_tensor, tau_tensor, t2_tensor, x_real_fast, y_real_fast, z_real_fast, x_real_slow, y_real_slow, z_real_slow,x_real_fast2, y_real_fast2, z_real_fast2, x_init, y_init, z_init, x1, y1, z1, x_end, y_end, z_end, eps, weight_fast=1.0, weight_slow=1.0):\n    loss_fast = loss_func_fast(model_fast, t_tensor, x_real_fast, y_real_fast, z_real_fast, x_init, y_init, z_init, x1, y1, z_exact_fast[-1], eps)\n    loss_slow = loss_func_slow(model_slow, tau_tensor, x_real_slow, y_real_slow, z_real_slow, x1, y1, z1, x_exact_slow[-1],y_exact_slow[-1],z_exact_slow[-1], eps)\n    loss_fast2 = loss_func_fast2(model_fast2, t2_tensor, x_real_fast2, y_real_fast2, z_real_fast2, x_end, y_end, z_end, x_exact_slow[-1],y_exact_slow[-1],z_exact_slow[-1], eps)\n    total_loss = weight_fast * loss_fast + weight_slow * loss_slow + weight_fast * loss_fast2\n    return total_loss\n\n\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}