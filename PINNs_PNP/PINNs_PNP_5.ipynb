{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom functools import partial\nfrom scipy.integrate import odeint\nfrom sympy import symbols, Eq, solve, Function, Matrix, diff\n\n# Define the ODE systems\ndef fast_system(y, t, eps):\n    phi, u, c1, c2, j1, j2, w = y\n    dphidt = u \n    dudt   = -z1 * c1 - z2 * c2\n    dc1dt  = -z1 * c1 * u - eps * j1\n    dc2dt  = -z2 * c2 * u - eps * j2\n    dj1dt  = 0\n    dj2dt  = 0\n    dwdt   = eps\n    \n    return [dphidt, dudt, dc1dt, dc2dt, dj1dt, dj2dt, dwdt]\n\n\ndef subfast_system(y, t, eps):\n    phi, u, c1, c2, j1, j2, w = y\n    dphidt = u \n    dudt   = -z1 * c1 - z2 * c2\n    dc1dt  = -z1 * c1 * u \n    dc2dt  = -z2 * c2 * u \n    dj1dt  = 0\n    dj2dt  = 0\n    dwdt   = 0\n    \n    return [dphidt, dudt, dc1dt, dc2dt, dj1dt, dj2dt, dwdt]\n\n\n\nt_end = 20\nt   =  np.linspace(0, t_end, 100)\nt2  =  np.linspace(0,-t_end, 100)\neps = 0.001\nT_slow_end = 1\ntau = np.linspace(0, T_slow_end, 100)\n\nt_tensor = torch.tensor(t.reshape(-1, 1), dtype=torch.float64) \ntau_tensor = torch.tensor(tau.reshape(-1, 1), dtype=torch.float64)\nt2_tensor = torch.tensor(t2.reshape(-1, 1), dtype=torch.float64)\n\n\ndef input_transform(t_tensor):\n    return torch.cat([t_tensor], dim=1)\n\nnum_nrn = 7\n\nclass fast_system_PINN(nn.Module):\n    def __init__(self):\n        super(fast_system_PINN, self).__init__()\n        self.fc1 = nn.Linear(1, num_nrn)\n        self.fc2 = nn.Linear(num_nrn, num_nrn)\n        self.fc3 = nn.Linear(num_nrn, 7)\n\n    def forward(self, t):\n        x = F.tanh(self.fc1(t))\n        x = F.tanh(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nclass slow_system_PINN(nn.Module):\n    def __init__(self):\n        super(slow_system_PINN, self).__init__()\n        self.fc1 = nn.Linear(1, num_nrn)\n        self.fc2 = nn.Linear(num_nrn, num_nrn)\n        self.fc3 = nn.Linear(num_nrn, 7)\n\n    def forward(self, tau):\n        x = F.tanh(self.fc1(tau))\n        x = F.tanh(self.fc2(x))\n        x = self.fc3(x)\n        return x\n      \nclass fast_system_PINN2(nn.Module):\n    def __init__(self):\n        super(fast_system_PINN2, self).__init__()\n        self.fc1 = nn.Linear(1, num_nrn)\n        self.fc2 = nn.Linear(num_nrn, num_nrn)\n        self.fc3 = nn.Linear(num_nrn, 7)\n\n    def forward(self, t2):\n        x = F.tanh(self.fc1(t2))\n        x = F.tanh(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-13T06:46:31.297668Z","iopub.execute_input":"2024-06-13T06:46:31.298061Z","iopub.status.idle":"2024-06-13T06:46:33.322421Z","shell.execute_reply.started":"2024-06-13T06:46:31.298029Z","shell.execute_reply":"2024-06-13T06:46:33.321297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z1, z2 = 1.0 , -1.0\nV  = -10\nl  = 0.7\nl1 , l2 = l , l\n\nr  = 0.5\nr1 , r2 = r , r\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T06:46:33.324684Z","iopub.execute_input":"2024-06-13T06:46:33.325244Z","iopub.status.idle":"2024-06-13T06:46:33.330846Z","shell.execute_reply.started":"2024-06-13T06:46:33.325204Z","shell.execute_reply":"2024-06-13T06:46:33.329741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initial points:\nphi_init, c1_init, c2_init,  w_init = V, l1 , -l2, 0.0  \nprint('The initial points of the BVP:', f\"phi_init = {phi_init}, c1_init  = {c1_init}, c2_init = {c2_init}, w_init   = {w_init} \")\n\nphi_slow_init, phi_slow_end = V, 0.0\nc1_slow_init, c1_slow_end   = l1, r1 \nc2_slow_init, c2_slow_end  = l2, r2\nw_slow_init, w_slow_end  = 0.0, 1.0\n\nphi_end, c1_end, c2_end, w_end = 0.0, r1, -r2 , 1.0\nprint('The ending points of the BVP:', f\"phi_end = {phi_end}, c1_end  = {c1_end}, c2_end = {c2_end}, w_end   = {w_end} \")\n \nJ1, J2    =  np.random.uniform(-2, 0), np.random.uniform(0, 2)\nu_a, u_b =  0.0, 0.0","metadata":{"execution":{"iopub.status.busy":"2024-06-13T06:46:33.332254Z","iopub.execute_input":"2024-06-13T06:46:33.332685Z","iopub.status.idle":"2024-06-13T06:46:33.343087Z","shell.execute_reply.started":"2024-06-13T06:46:33.332647Z","shell.execute_reply":"2024-06-13T06:46:33.341950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phys_weight  = 1\ninit_weight  = 1\nbndry_weight = 1\ndef loss_func_fast(model, t_tensor, phi_init, c1_init, c2_init, w_init,\\\n                                    phi_slow_init, c1_slow_init, c2_slow_init, w_slow_init,\\\n                                    eps, random_points=10):\n    t_tensor.requires_grad = True\n    pred_fast = model(t_tensor)\n    phi_pred_fast, u_pred_fast = pred_fast[:, 0].unsqueeze(1), pred_fast[:, 1].unsqueeze(1)\n    c1_pred_fast, c2_pred_fast = pred_fast[:, 2].unsqueeze(1), pred_fast[:, 3].unsqueeze(1)\n    j1_pred_fast, j2_pred_fast = pred_fast[:, 4].unsqueeze(1), pred_fast[:, 5].unsqueeze(1)\n    w_pred_fast = pred_fast[:, 6].unsqueeze(1)\n    #ones = torch.ones_like(x_pred_fast, requires_grad=True)    \n    dphi_dt = torch.autograd.grad(phi_pred_fast.sum(), t_tensor, retain_graph=True, create_graph=True)[0]\n    du_dt = torch.autograd.grad(u_pred_fast.sum(), t_tensor, retain_graph=True, create_graph=True)[0]\n    dc1_dt = torch.autograd.grad(c1_pred_fast.sum(), t_tensor, retain_graph=True, create_graph=True)[0]\n    dc2_dt = torch.autograd.grad(c2_pred_fast.sum(), t_tensor, retain_graph=True, create_graph=True)[0]\n    dj1_dt = torch.autograd.grad(j1_pred_fast.sum(), t_tensor, retain_graph=True, create_graph=True)[0]\n    dj2_dt = torch.autograd.grad(j2_pred_fast.sum(), t_tensor, retain_graph=True, create_graph=True)[0]\n    dw_dt = torch.autograd.grad(w_pred_fast.sum(), t_tensor, retain_graph=True, create_graph=True)[0]\n    \n    #for the fast system\n    residual1_fast =  dphi_dt - u_pred_fast\n    residual2_fast =  du_dt + z1 * c1_pred_fast + z2 * c2_pred_fast\n    residual3_fast =  dc1_dt + z1 * c1_pred_fast * u_pred_fast #+ eps * j1_pred_fast\n    residual4_fast =  dc2_dt + z2 * c2_pred_fast * u_pred_fast #+ eps * j2_pred_fast\n    residual5_fast =  dj1_dt  \n    residual6_fast =  dj2_dt \n    residual7_fast =  dw_dt #- eps\n    \n    init_loss_fast = torch.square(phi_pred_fast[0] - phi_init) +\\\n                     torch.square(c1_pred_fast[0] - c1_init)  +\\\n                     torch.square(c2_pred_fast[0] - c2_init)  +\\\n                     torch.square(w_pred_fast[0] - w_init)  \n    \n    physics_loss_fast = torch.mean(residual1_fast**2 + residual2_fast**2 +\\\n                                   residual3_fast**2 + residual4_fast**2 +\\\n                                   residual5_fast**2 + residual6_fast**2 +\\\n                                   residual7_fast**2)\n    boundary_loss_fast = torch.square(phi_pred_fast[-1] - phi_slow_init) +\\\n                         torch.square(u_pred_fast[-1] - u_a) +\\\n                         torch.square(c1_pred_fast[-1] - c1_slow_init) +\\\n                         torch.square(c2_pred_fast[-1] - c2_slow_init) +\\\n                         torch.square(w_pred_fast[-1] - w_slow_init) \n    J1 = j1_pred_fast[-1]\n    J2 = j2_pred_fast[-1]\n    if epoch % 1000 == 0:\n        print(J1)\n        print(J2)\n        \n    total_loss_fast   = phys_weight * physics_loss_fast +\\\n                        init_weight * init_loss_fast + bndry_weight * boundary_loss_fast\n    return total_loss_fast\n\ndef loss_func_slow(model, tau_tensor, eps, random_points=10):\n    tau_tensor.requires_grad = True\n    pred_slow = model(tau_tensor)\n    phi_pred_slow, u_pred_slow = pred_slow[:, 0].unsqueeze(1), pred_slow[:, 1].unsqueeze(1)\n    c1_pred_slow, c2_pred_slow = pred_slow[:, 2].unsqueeze(1), pred_slow[:, 3].unsqueeze(1)\n    j1_pred_slow, j2_pred_slow = pred_slow[:, 4].unsqueeze(1), pred_slow[:, 5].unsqueeze(1)\n    w_pred_slow = pred_slow[:, 6].unsqueeze(1)\n    #ones = torch.ones_like(x_pred_fast, requires_grad=True)    \n    dphi_dtau = torch.autograd.grad(phi_pred_slow.sum(), tau_tensor, retain_graph=True, create_graph=True)[0]\n    du_dtau = torch.autograd.grad(u_pred_slow.sum(), tau_tensor, retain_graph=True, create_graph=True)[0]\n    dc1_dtau = torch.autograd.grad(c1_pred_slow.sum(), tau_tensor, retain_graph=True, create_graph=True)[0]\n    dc2_dtau = torch.autograd.grad(c2_pred_slow.sum(), tau_tensor, retain_graph=True, create_graph=True)[0]\n    dj1_dtau = torch.autograd.grad(j1_pred_slow.sum(), tau_tensor, retain_graph=True, create_graph=True)[0]\n    dj2_dtau = torch.autograd.grad(j2_pred_slow.sum(), tau_tensor, retain_graph=True, create_graph=True)[0]\n    dw_dtau = torch.autograd.grad(w_pred_slow.sum(), tau_tensor, retain_graph=True, create_graph=True)[0]\n    \n    #for the fast system\n    p = - (z1 * j1_pred_slow + z2 * j2_pred_slow)/(z1 * (z1 - z2) * c1_pred_slow)\n    #p2 = (z1 * j1_pred_slow + z2 * j2_pred_slow) #/(z1 * (z1 - z2) * c1_pred_slow)\n        \n    residual1_slow = u_pred_slow #- eps * p\n    residual2_slow = dphi_dtau - p\n    residual3_slow = dc1_dtau + z1 * c1_pred_slow * p + j1_pred_slow #* (z1 - z2)*z1*c1_pred_slow\n    residual4_slow = dc2_dtau + z2 * c2_pred_slow * p + j2_pred_slow #* (z1 - z2)*z1*c1_pred_slow\n    residual5_slow = dj1_dtau\n    residual6_slow = dj2_dtau \n    residual7_slow = dw_dtau - 1 # - (z1 - z2) * z1 * c1_pred_slow\n    residual8_slow = z1 * c1_pred_slow + z2 * c2_pred_slow\n    \n    #residual1_slow = dphi_dtau - u_pred_slow\n    #residual2_slow = du_dtau \n    #residual3_slow = dc1_dtau  + z1 * c1_pred_slow * u_pred_slow \n    #residual4_slow = dc2_dtau  + z2 * c2_pred_slow * u_pred_slow \n       \n    \n    init_loss_slow = torch.square(phi_pred_slow[0] - phi_slow_init) +\\\n                     torch.square(u_pred_slow[0] - u_a) +\\\n                     torch.square(c1_pred_slow[0] - c1_slow_init)  +\\\n                     torch.square(c2_pred_slow[0] - c2_slow_init)  +\\\n                     torch.square(w_pred_slow[0] - w_slow_init)  \n    \n    physics_loss_slow = torch.mean(residual1_slow**2 + residual2_slow**2 +\\\n                                   residual3_slow**2 + residual4_slow**2 +\\\n                                   residual5_slow**2 + residual6_slow**2 +\\\n                                   residual7_slow**2 + residual8_slow**2)\n    boundary_loss_slow =  torch.square(j1_pred_slow[0] - J1)  +\\\n                          torch.square(j2_pred_slow[0] - J2)  +\\\n                          torch.square(j1_pred_slow[-1] - J1)  +\\\n                          torch.square(j2_pred_slow[-1] - J2)  +\\\n                          torch.square(u_pred_slow[-1] - u_b)\n    \n    #u_b = u_pred_slow[-1]\n    \n    total_loss_fast   = phys_weight * physics_loss_slow +\\\n                        init_weight * init_loss_slow + bndry_weight * boundary_loss_slow\n    return total_loss_fast\n\n\ndef loss_func_fast2(model, t2_tensor, phi_end, c1_end, c2_end, w_end,\\\n                                    phi_slow_end, c1_slow_end, c2_slow_end, w_slow_end,\\\n                                    eps, random_points=10):\n    t2_tensor.requires_grad = True\n    pred_fast2 = model(t2_tensor)\n    phi_pred_fast2, u_pred_fast2 = pred_fast2[:, 0].unsqueeze(1), pred_fast2[:, 1].unsqueeze(1)\n    c1_pred_fast2, c2_pred_fast2 = pred_fast2[:, 2].unsqueeze(1), pred_fast2[:, 3].unsqueeze(1)\n    j1_pred_fast2, j2_pred_fast2 = pred_fast2[:, 4].unsqueeze(1), pred_fast2[:, 5].unsqueeze(1)\n    w_pred_fast2 = pred_fast2[:, 6].unsqueeze(1)\n    #ones = torch.ones_like(x_pred_fast, requires_grad=True)    \n    dphi_dt2 = torch.autograd.grad(phi_pred_fast2.sum(), t2_tensor, retain_graph=True, create_graph=True)[0]\n    du_dt2 = torch.autograd.grad(u_pred_fast2.sum(), t2_tensor, retain_graph=True, create_graph=True)[0]\n    dc1_dt2 = torch.autograd.grad(c1_pred_fast2.sum(), t2_tensor, retain_graph=True, create_graph=True)[0]\n    dc2_dt2 = torch.autograd.grad(c2_pred_fast2.sum(), t2_tensor, retain_graph=True, create_graph=True)[0]\n    dj1_dt2 = torch.autograd.grad(j1_pred_fast2.sum(), t2_tensor, retain_graph=True, create_graph=True)[0]\n    dj2_dt2 = torch.autograd.grad(j2_pred_fast2.sum(), t2_tensor, retain_graph=True, create_graph=True)[0]\n    dw_dt2 = torch.autograd.grad(w_pred_fast2.sum(), t2_tensor, retain_graph=True, create_graph=True)[0]\n    \n    #for the fast system\n    residual1_fast2 =  dphi_dt2 - u_pred_fast2\n    residual2_fast2 =  du_dt2 + z1 * c1_pred_fast2 + z2 * c2_pred_fast2\n    residual3_fast2 =  dc1_dt2 + z1 * c1_pred_fast2 * u_pred_fast2 #+ eps * j1_pred_fast2\n    residual4_fast2 =  dc2_dt2 + z2 * c2_pred_fast2 * u_pred_fast2 #+ eps * j2_pred_fast2\n    residual5_fast2 =  dj1_dt2  \n    residual6_fast2 =  dj2_dt2 \n    residual7_fast2 =  dw_dt2 #- eps\n    \n    init_loss_fast2 = torch.square(phi_pred_fast2[0] - phi_end) +\\\n                      torch.square(c1_pred_fast2[0] - c1_end)  +\\\n                      torch.square(c2_pred_fast2[0] - c2_end)  +\\\n                      torch.square(w_pred_fast2[0] - w_end)  \n    \n    physics_loss_fast2 = torch.mean(residual1_fast2**2 + residual2_fast2**2 +\\\n                                   residual3_fast2**2 + residual4_fast2**2 +\\\n                                   residual5_fast2**2 + residual6_fast2**2 +\\\n                                   residual7_fast2**2)\n    boundary_loss_fast2 = torch.square(phi_pred_fast2[-1] - phi_slow_end) +\\\n                          torch.square(u_pred_fast2[-1] - u_b) +\\\n                          torch.square(c1_pred_fast2[-1] - c1_slow_end) +\\\n                          torch.square(c2_pred_fast2[-1] - c2_slow_end) +\\\n                          torch.square(j1_pred_fast2[-1] - J1) +\\\n                          torch.square(j2_pred_fast2[-1] - J2) +\\\n                          torch.square(w_pred_fast2[-1] - w_slow_end) \n    \n    total_loss_fast2   = phys_weight * physics_loss_fast2 +\\\n                         init_weight * init_loss_fast2 + bndry_weight * boundary_loss_fast2\n    return total_loss_fast2\n\n\ndef total_loss_func(model_fast, model_slow, model_fast2, t_tensor, tau_tensor, t2_tensor,\\\n                    phi_init, c1_init, c2_init, w_init,\\\n                    phi_slow_init, c1_slow_init, c2_slow_init, w_slow_init,\\\n                    phi_end, c1_end, c2_end, w_end,\\\n                    phi_slow_end, c1_slow_end, c2_slow_end, w_slow_end,\\\n                    eps, weight_fast=1.0, weight_slow=1.0):\n    loss_fast = loss_func_fast(model_fast, t_tensor, phi_init, c1_init, c2_init, w_init,\\\n                               phi_slow_init, c1_slow_init, c2_slow_init, w_slow_init, eps)\n    loss_slow = loss_func_slow(model_slow, tau_tensor, eps)\n    loss_fast2 = loss_func_fast2(model_fast2, t2_tensor, phi_end, c1_end, c2_end, w_end,\\\n                                phi_slow_end, c1_slow_end, c2_slow_end, w_slow_end, eps)\n\n    total_loss = weight_fast * loss_fast + weight_slow * loss_slow + weight_fast * loss_fast2\n    \n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2024-06-13T06:46:33.345798Z","iopub.execute_input":"2024-06-13T06:46:33.346142Z","iopub.status.idle":"2024-06-13T06:46:33.385488Z","shell.execute_reply.started":"2024-06-13T06:46:33.346106Z","shell.execute_reply":"2024-06-13T06:46:33.384317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__=='__main__':\n\n    model_fast  = fast_system_PINN().to(torch.float64)  \n    model_slow  = slow_system_PINN().to(torch.float64)  \n    model_fast2 = fast_system_PINN2().to(torch.float64) \n\n    optimizer = torch.optim.Adam(list(model_fast.parameters()) +\\\n                                 list(model_slow.parameters()) +\\\n                                 list(model_fast2.parameters()), lr=1e-3)\n    loss_values = []\n    epoch_num = 100000\n\n    #xf2_end, yf2_end =  np.random.uniform(1, 2) , np.random.uniform(-1, 0) #-1, 2 #\n\n    for epoch in range(epoch_num):\n        optimizer.zero_grad()\n        loss_total = total_loss_func(model_fast, model_slow, model_fast2,\\\n                                    t_tensor, tau_tensor, t2_tensor,\\\n                                    phi_init, c1_init, c2_init, w_init,\\\n                                    phi_slow_init, c1_slow_init, c2_slow_init, w_slow_init,\\\n                                    phi_end, c1_end, c2_end, w_end,\\\n                                    phi_slow_end, c1_slow_end, c2_slow_end, w_slow_end,\\\n                                    eps, weight_fast=1.0, weight_slow=1.0)\n        loss_total.backward()#(retain_graph=True)\n        optimizer.step()\n        with torch.no_grad():\n            phi_pred_fast, u_pred_fast, c1_pred_fast, c2_pred_fast, j1_pred_fast, j2_pred_fast, w_pred_fast = model_fast(t_tensor).numpy().T\n            phi_pred_slow, u_pred_slow, c1_pred_slow, c2_pred_slow, j1_pred_slow, j2_pred_slow, w_pred_slow = model_slow(tau_tensor).numpy().T\n            phi_pred_fast2, u_pred_fast2, c1_pred_fast2, c2_pred_fast2, j1_pred_fast2, j2_pred_fast2, w_pred_fast2 = model_fast2(t2_tensor).numpy().T\n            #J1, J2   = j1_pred_slow[0], j2_pred_slow[0]\n            #u_a, u_b = u_pred_fast[-1], u_pred_fast2[-1]\n\n        if epoch % 1000 == 0:\n            print(f'Epoch {epoch}, Total Loss: {loss_total.item()}') \n        loss_values.append(loss_total.item())\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(12, 4))\n    plt.plot(range(0, epoch_num, 1000), np.log(loss_values[:epoch_num//1000]), 'b', label='Fast System')\n    plt.xlabel('Epoch')\n    plt.ylabel('Log(Loss)')\n    plt.title('Training Loss Over Epochs (Fast System)')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n    # Model evaluation\n    model_fast.eval()\n    model_slow.eval()\n    model_fast2.eval()\n    with torch.no_grad():\n        # Predictions for fast system\n        phi_pred_fast, u_pred_fast, c1_pred_fast, c2_pred_fast, j1_pred_fast, j2_pred_fast, w_pred_fast = model_fast(t_tensor).numpy().T\n        phi_pred_slow, u_pred_slow, c1_pred_slow, c2_pred_slow, j1_pred_slow, j2_pred_slow, w_pred_slow = model_slow(tau_tensor).numpy().T\n        phi_pred_fast2, u_pred_fast2, c1_pred_fast2, c2_pred_fast2, j1_pred_fast2, j2_pred_fast2, w_pred_fast2 = model_fast2(t2_tensor).numpy().T\n             \n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-13T06:46:33.387264Z","iopub.execute_input":"2024-06-13T06:46:33.387927Z","iopub.status.idle":"2024-06-13T07:05:52.923042Z","shell.execute_reply.started":"2024-06-13T06:46:33.387887Z","shell.execute_reply":"2024-06-13T07:05:52.921759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(u_pred_fast[0], j1_pred_fast[0], 'go', label='Initial point')\n# Plot numerical (fast)\nplt.plot(u_pred_fast, j1_pred_fast, 'b--', label='Numerical (Fast)')\nplt.plot(u_pred_slow, j1_pred_slow, 'r--', label='Numerical (Slow)')\nplt.plot(u_pred_fast2, j1_pred_fast2, 'm--', label='Numerical (Fast)')#, alpha=0.5)\n\n# Plot ending point\nplt.plot(u_pred_fast2[0], j1_pred_fast2[0], 'ro', label='Ending point')\nplt.xlabel('$u$')\nplt.ylabel('$J_1$')\n#plt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(u_pred_fast[0], j2_pred_fast[0], 'go', label='Initial point')\n# Plot numerical (fast)\nplt.plot(u_pred_fast, j2_pred_fast, 'b--', label='Numerical (Fast)')\nplt.plot(u_pred_slow, j2_pred_slow, 'r--', label='Numerical (Slow)')\nplt.plot(u_pred_fast2, j2_pred_fast2, 'm--', label='Numerical (Fast)')#, alpha=0.5)\n\n# Plot ending point\nplt.plot(u_pred_fast2[0], j2_pred_fast2[0], 'ro', label='Ending point')\nplt.legend()\nplt.xlabel('$u$')\nplt.ylabel('$J_2$')\n\nplt.grid(True, alpha=0.1)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:05:52.924372Z","iopub.execute_input":"2024-06-13T07:05:52.924814Z","iopub.status.idle":"2024-06-13T07:05:53.559903Z","shell.execute_reply.started":"2024-06-13T07:05:52.924784Z","shell.execute_reply":"2024-06-13T07:05:53.558811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(J1)\nprint(J2)\nprint(j2_pred_fast.shape)\nprint(j2_pred_fast[0])\nprint(j2_pred_fast[-1])\nprint('')\n\nprint(j2_pred_slow[0])\nprint(j2_pred_slow[-1])\nprint('')\n\nprint(j2_pred_fast2[0])\nprint(j2_pred_fast2[-1])","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:05:53.561733Z","iopub.execute_input":"2024-06-13T07:05:53.562076Z","iopub.status.idle":"2024-06-13T07:05:53.568209Z","shell.execute_reply.started":"2024-06-13T07:05:53.562047Z","shell.execute_reply":"2024-06-13T07:05:53.566981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 3, 1)\nplt.plot(t, u_pred_fast, '--', color='blue', label='Predicted $u$')\nplt.xlabel('$x$')\nplt.ylabel('$u$')\nplt.title(' Over the first piece')\nplt.grid(True, alpha=0.1)\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(tau, u_pred_slow, '--', color='blue', label='Predicted $u$')\nplt.xlabel('$x$')\nplt.ylabel('$u$')\nplt.title(' Over the slow manifold')\nplt.grid(True, alpha=0.1)\nplt.legend()\n\n\nplt.subplot(1, 3, 3)\nplt.plot(t2, u_pred_fast2 , '--', color='blue', label='Predicted $u$')\nplt.xlabel('$x$')\nplt.ylabel('$u$')\nplt.title(' Over the 3rd piece')\nplt.legend()\nplt.grid(True, alpha=0.1)\n\nplt.tight_layout()\nplt.show()\n\n########\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 3, 1)\nplt.plot(t, j1_pred_fast, 'r--', label='Predicted $J_1$')\nplt.xlabel('$x$')\nplt.ylabel('$J_1$')\nplt.title(' Over the first piece')\nplt.grid(True, alpha=0.1)\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(tau, j1_pred_slow, 'r--', label='Predicted $J_1$')\nplt.xlabel('$x$')\nplt.ylabel('$J_1$')\nplt.title('  Over the slow manifold')\nplt.grid(True, alpha=0.1)\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(t2, j1_pred_fast2 , 'r--', label='Predicted $J_1$')\nplt.xlabel('$x$')\nplt.ylabel('$J_1$')\nplt.title(' Over the 3rd piece')\nplt.legend()\n\nplt.grid(True, alpha=0.1)\nplt.tight_layout()\nplt.show()\n\n########\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 3, 1)\nplt.plot(t, j2_pred_fast, 'm--', label='Predicted $J_2$')\nplt.xlabel('$x$')\nplt.ylabel('$J_2$')\nplt.title(' Over the first piece')\nplt.grid(True, alpha=0.1)\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(tau, j2_pred_slow, 'm--', label='Predicted $J_2$')\nplt.xlabel('$x$')\nplt.ylabel('$J_2$')\nplt.title(' Over the slow manifold')\nplt.grid(True, alpha=0.1)\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(t2, j2_pred_fast2 , 'm--', label='Predicted $J_2$')\nplt.xlabel('$x$')\nplt.ylabel('$J_2$')\nplt.title(' Over the 3rd piece')\nplt.legend()\n\nplt.grid(True, alpha=0.1)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:05:53.569860Z","iopub.execute_input":"2024-06-13T07:05:53.570262Z","iopub.status.idle":"2024-06-13T07:05:55.672765Z","shell.execute_reply.started":"2024-06-13T07:05:53.570225Z","shell.execute_reply":"2024-06-13T07:05:55.671577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\n\nplt.subplot(1, 3, 1)\nplt.plot(t, z1 * c1_pred_fast + z2 * c2_pred_fast, 'm--', label='Predicted $z_1 c_1+ z_2  c_2$')\nplt.xlabel('$x$')\nplt.ylabel('$z_1 c_1+ z_2  c_2$')\nplt.title(' Over the first piece')\nplt.grid(True, alpha=0.1)\nplt.legend()\n\nzc_slow_init = z1 * c1_pred_fast[-1] + z2 * c2_pred_fast[-1]\nplt.subplot(1, 3, 2)\nplt.plot(tau, z1 * c1_pred_slow + z2 * c2_pred_slow + zc_slow_init, 'm--', label='Predicted $z_1 c_1+ z_2  c_2$')\nplt.xlabel('$x$')\n#plt.ylabel('$z_1 c_1+ z_2  c_2$')\nplt.title(' Over the slow manifold')\nplt.grid(True, alpha=0.1)\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(t2, z1 * c1_pred_fast2 + z2 * c2_pred_fast2 , 'm--', label='Predicted $z_1 c_1+ z_2  c_2$')\nplt.xlabel('$x$')\nplt.ylabel('$z_1 c_1+ z_2  c_2$')\nplt.title(' Over the 3rd piece')\nplt.legend()\n\nplt.grid(True, alpha=0.1)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:36:02.534238Z","iopub.execute_input":"2024-06-13T07:36:02.534652Z","iopub.status.idle":"2024-06-13T07:36:03.450653Z","shell.execute_reply.started":"2024-06-13T07:36:02.534621Z","shell.execute_reply":"2024-06-13T07:36:03.449719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure(figsize=(12, 6))\nax = fig.add_subplot(111, projection='3d')\n\nax.plot(w_init, u_pred_fast[0], z1 * c1_init + z2 * c2_init, 'go', label='Initial point')\n\nax.plot(w_pred_fast, u_pred_fast, z1 * c1_pred_fast + z2 * c2_pred_fast, 'b--', label='PINN prediction (Fast)')\n\n\nax.plot(w_pred_slow + w_pred_fast[-1],\\\n        u_pred_slow + u_a,\\\n        z1 * c1_pred_slow + z2 * c2_pred_slow + z1 * c1_slow_init + z2 * c2_slow_init,\\\n        'k--', label='PINN prediction (Slow)', alpha=0.5)\n\n\nax.plot(w_pred_fast2 , u_pred_fast2 , z1 * c1_pred_fast2 + z2 * c2_pred_fast2 ,\\\n                                        'm--', label='PINN prediction (Fast)', alpha=0.5)\nax.plot(w_end, u_pred_fast2[0], z1 * c1_end + z2 * c2_end, 'ro', label='Ending point')\n\nax.set_xlabel('$x$')\nax.set_ylabel('$u$')\nax.set_zlabel('$z_1 c_1 + z_2 c_2$', labelpad=1)\n#ax.set_title('Combined Fast and Slow Systems')\nax.legend()\nax.invert_xaxis()\n\n# Adjust the position of the legend box\n#ax.legend(prop={'size': 5})  # Set font size to 10 points\n#ax.legend(bbox_to_anchor=(0.45, 0.85))\nax.legend(prop={'size': 9}, bbox_to_anchor=(0.45, 0.85))\n\n# Adjust the transparency of the grid\nax.xaxis._axinfo['grid'].update(color=(0.1, 0.1, 0.1, 0.1))  # RGBA: last value is alpha\nax.yaxis._axinfo['grid'].update(color=(0.1, 0.1, 0.1, 0.1))\nax.zaxis._axinfo['grid'].update(color=(0.1, 0.1, 0.1, 0.1))\n\n# Rotating the figure by 20 degrees\nax.view_init(elev=20, azim=120)\n\nplt.grid(True, alpha=0.1)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T07:05:56.340409Z","iopub.execute_input":"2024-06-13T07:05:56.340843Z","iopub.status.idle":"2024-06-13T07:05:56.633222Z","shell.execute_reply.started":"2024-06-13T07:05:56.340812Z","shell.execute_reply":"2024-06-13T07:05:56.632141Z"},"trusted":true},"execution_count":null,"outputs":[]}]}