{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom functools import partial\nfrom scipy.integrate import odeint\nfrom sympy import symbols, Eq, solve, Function, Matrix, diff\n\n# Constants and Parameters\nt_end = 20\nt1 = np.linspace(0, t_end, 100)\nt2 = np.linspace(0, t_end, 100)\neps = 0.01\nT_slow_end = 1\ntau1 = np.linspace(0, T_slow_end, 100)\ntau2 = np.linspace(0, T_slow_end, 100)\ntau3 = np.linspace(0, T_slow_end, 100)\n\n# Convert to tensors\ntau1_tensor = torch.tensor(tau1.reshape(-1, 1), dtype=torch.float64)\nt1_tensor = torch.tensor(t1.reshape(-1, 1), dtype=torch.float64)\ntau2_tensor = torch.tensor(tau2.reshape(-1, 1), dtype=torch.float64)\nt2_tensor = torch.tensor(t2.reshape(-1, 1), dtype=torch.float64)\ntau3_tensor = torch.tensor(tau3.reshape(-1, 1), dtype=torch.float64)\n\n# Model parameters\nnum_nrn = 7\nz1, z2 = 1.0, -1.0\nV = -10\nl = 1.0\nr = 0.5\nphi_init, c1_init, c2_init, w_init = V, l, l, 0.0\nphi_end, c1_end, c2_end, w_end = 0.0, r, r, 1.0\n\n# Neural Network Models\nclass PINN(nn.Module):\n    \"\"\"Generic PINN model for both slow and fast systems.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(1, num_nrn)\n        self.fc2 = nn.Linear(num_nrn, num_nrn)\n        self.fc3 = nn.Linear(num_nrn, 7)\n\n    def forward(self, x):\n        x = torch.tanh(self.fc1(x))\n        x = torch.tanh(self.fc2(x))\n        return self.fc3(x)\n\n# Initialize models\nmodel_slow1 = PINN().double()\nmodel_fast1 = PINN().double()\nmodel_slow2 = PINN().double()\nmodel_fast2 = PINN().double()\nmodel_slow3 = PINN().double()\n\n# Initialize coupling variables\ncoupling_vars = {\n    'c1_s_a_l': np.random.uniform(0, 1),\n    'c2_s_a_l': np.random.uniform(0, 1),\n    'phi_s_a_l': np.random.uniform(0, 1),\n    # ... initialize all coupling variables similarly\n}\n\n# Loss configuration\nphys_weight = 3\ninit_weight = 1\nbndry_weight = 1\n\ndef compute_residuals(model, inputs, system_type, eps=None):\n    \"\"\"Compute physics residuals for given system type.\"\"\"\n    inputs.requires_grad = True\n    pred = model(inputs)\n    phi, u = pred[:, 0], pred[:, 1]\n    c1, c2 = pred[:, 2], pred[:, 3]\n    j1, j2, w = pred[:, 4], pred[:, 5], pred[:, 6]\n\n    # Compute gradients\n    gradients = {}\n    for var in [phi, u, c1, c2, j1, j2, w]:\n        var.sum().backward(retain_graph=True, create_graph=True)\n        gradients[var] = inputs.grad.clone()\n        inputs.grad.zero_()\n\n    # System-specific residuals\n    if system_type == 'slow':\n        p = -(z1*j1 + z2*j2) / (z1*(z1-z2)*c1)\n        residuals = [\n            u,  # residual1\n            gradients[phi] - p,\n            gradients[c1] + z1*c1*p + j1,\n            gradients[c2] + z2*c2*p + j2,\n            gradients[j1],\n            gradients[j2],\n            gradients[w] - 1,\n            z1*c1 + z2*c2\n        ]\n    elif system_type == 'fast':\n        residuals = [\n            gradients[phi] - u,\n            gradients[u] + z1*c1 + z2*c2,\n            gradients[c1] + z1*c1*u + eps*j1,\n            gradients[c2] + z2*c2*u + eps*j2,\n            gradients[j1],\n            gradients[j2],\n            gradients[w] - eps\n        ]\n    \n    # Non-negativity constraints\n    non_neg = [torch.clamp(-c1, min=0), torch.clamp(-c2, min=0)]\n    return residuals, non_neg, pred\n\ndef create_loss_func(system_type, init_conds, boundary_conds, eps=None):\n    \"\"\"Factory function to create loss functions.\"\"\"\n    def loss_func(model, inputs, eps=None):\n        residuals, non_neg, pred = compute_residuals(model, inputs, system_type, eps)\n        # Calculate initialization and boundary losses\n        # ... implementation details\n        return total_loss\n    return loss_func\n\n# Training loop\ndef train_models(models, optimizers, epochs=20000):\n    loss_history = []\n    for epoch in range(epochs):\n        # Training step\n        # ... implement training logic\n        \n        # Update coupling variables\n        with torch.no_grad():\n            # ... update coupling variables using current model predictions\n        \n        # Logging\n        if epoch % 1000 == 0:\n            print(f'Epoch {epoch}, Loss: {loss.item()}')\n            loss_history.append(loss.item())\n    return loss_history\n\n# Main execution\nif __name__ == '__main__':\n    # Initialize models and optimizers\n    models = [model_slow1, model_fast1, model_slow2, model_fast2, model_slow3]\n    optimizer = torch.optim.Adam(\n        [p for model in models for p in model.parameters()], \n        lr=1e-3\n    )\n    \n    # Define loss functions for each system\n    loss_func_slow1 = create_loss_func('slow', init_conds=(phi_init, c1_init, c2_init, w_init), \n                                      boundary_conds=(phi_f_a_l, c1_f_a_l, c2_f_a_l, w_a), eps=eps)\n    loss_func_fast1 = create_loss_func('fast', init_conds=(c1_s_a_l, c2_s_a_l, w_a), \n                                      boundary_conds=(phi_s_a_r, c1_s_a_r, c2_s_a_r, w_a), eps=eps)\n    loss_func_slow2 = create_loss_func('slow', init_conds=(phi_f_a_r, c1_f_a_r, c2_f_a_r, w_a), \n                                      boundary_conds=(phi_f_b_l, c1_f_b_l, c2_f_b_l, w_b), eps=eps)\n    loss_func_fast2 = create_loss_func('fast', init_conds=(c1_s_b_l, c2_s_b_l, w_b), \n                                      boundary_conds=(phi_s_b_r, c1_s_b_r, c2_s_b_r, w_b), eps=eps)\n    loss_func_slow3 = create_loss_func('slow', init_conds=(phi_f_b_r, c1_f_b_r, c2_f_b_r, w_b), \n                                      boundary_conds=(phi_end, c1_end, c2_end, w_end), eps=eps)\n    \n    # Train models\n    loss_values = train_models(models, optimizer)\n    \n    # Plot results\n    plt.figure(figsize=(12, 4))\n    plt.plot(np.log(loss_values))\n    plt.xlabel('Epoch (x1000)')\n    plt.ylabel('Log(Loss)')\n    plt.title('Training Loss')\n    plt.grid(True)\n    plt.show()\n\n    # Final evaluation\n    with torch.no_grad():\n        # Predictions for all systems\n        pred_slow1 = model_slow1(tau1_tensor).numpy()\n        pred_fast1 = model_fast1(t1_tensor).numpy()\n        pred_slow2 = model_slow2(tau2_tensor).numpy()\n        pred_fast2 = model_fast2(t2_tensor).numpy()\n        pred_slow3 = model_slow3(tau3_tensor).numpy()\n\n        # Extract predictions\n        phi_pred_slow1, u_pred_slow1, c1_pred_slow1, c2_pred_slow1, j1_pred_slow1, j2_pred_slow1, w_pred_slow1 = pred_slow1.T\n        phi_pred_fast1, u_pred_fast1, c1_pred_fast1, c2_pred_fast1, j1_pred_fast1, j2_pred_fast1, w_pred_fast1 = pred_fast1.T\n        phi_pred_slow2, u_pred_slow2, c1_pred_slow2, c2_pred_slow2, j1_pred_slow2, j2_pred_slow2, w_pred_slow2 = pred_slow2.T\n        phi_pred_fast2, u_pred_fast2, c1_pred_fast2, c2_pred_fast2, j1_pred_fast2, j2_pred_fast2, w_pred_fast2 = pred_fast2.T\n        phi_pred_slow3, u_pred_slow3, c1_pred_slow3, c2_pred_slow3, j1_pred_slow3, j2_pred_slow3, w_pred_slow3 = pred_slow3.T","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}